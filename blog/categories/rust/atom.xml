<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: rust | katsyoshiのめもみたいなもの]]></title>
  <link href="http://blog.katsyoshi.org/blog/categories/rust/atom.xml" rel="self"/>
  <link href="http://blog.katsyoshi.org/"/>
  <updated>2018-10-19T00:33:17+09:00</updated>
  <id>http://blog.katsyoshi.org/</id>
  <author>
    <name><![CDATA[katsyoshi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[NLP100 Knock Section IV]]></title>
    <link href="http://blog.katsyoshi.org/blog/2018/02/26/nlp-100-section-4/"/>
    <updated>2018-02-26T23:45:52+09:00</updated>
    <id>http://blog.katsyoshi.org/blog/2018/02/26/nlp-100-section-4</id>
    <content type="html"><![CDATA[<p>NLP100本ノック第4節おわりましたのでまとめます</p>

<h2><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#ch4">第4章 形態素解析</a></h2>

<p>形態素解析やからむずいやろとおもってた</p>

<h3>準備</h3>

<p>この章では、形態素解析済ファイルを作成する必要がありますが、毎回対象ファイルをダウンロード、解析して解いています。
ここではいつもどおり <code>HashMap</code> を利用するため <code>ANALYZED_MECAB_KEYS</code> を作成してこれをキーにします。
またよく利用する品詞を <code>enum</code> で定義しておき、変換関数 <code>inspect</code> を作成します。</p>

<p>```rust
const ANALYZED_MECAB_KEYS: [&str; 9] = [&ldquo;pos&rdquo;, &ldquo;pos1&rdquo;, &ldquo;pos2&rdquo;, &ldquo;pos3&rdquo;, &ldquo;a&rdquo;, &ldquo;b&rdquo;, &ldquo;base&rdquo;, &ldquo;read&rdquo;, &ldquo;speech&rdquo;];
enum PartOfSpeech {</p>

<pre><code>VERB,
NOUN,
PARTICLE,
</code></pre>

<p>}</p>

<p>use PartOfSpeech::*;</p>

<p>fn inspect(val: PartOfSpeech) &ndash;> String {</p>

<pre><code>match val {
    VERB =&gt; "動詞",
    NOUN =&gt; "名詞",
    PARTICLE =&gt; "助詞",
}.to_string()
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec30">30. 形態素解析結果の読み込み</a></h3>

<p><code>Map</code> を使えと指定があるので素直に利用します</p>

<p>```rust
fn feature(node: &amp;Node) &ndash;> HashMap&lt;String, String> {</p>

<pre><code>let mut h: HashMap&lt;String, String&gt; = HashMap::new();
let surface: String = (&amp;(node.surface)[..node.length as usize]).to_string();
h.insert("surface".to_string(), surface);
let values: Vec&lt;String&gt; = node.feature.split(",").map(|m| m.to_string()).collect();
for (a, b) in ANALYZED_MECAB_KEYS.iter().zip(values.iter()) {
    h.insert(a.to_string(), b.to_string());
}
h
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let url = "http://www.cl.ecei.tohoku.ac.jp/nlp100/data/neko.txt".to_string();
let neco: Vec&lt;String&gt; = NLP100::get(url).split("\n").filter(|f| f.ne(&amp;"")).map(|m| m.to_string()).collect();
let mut morph = Vec::new();

for line in neco {
    let mut tagger: Tagger = mecab::Tagger::new("");
    let nodes: Node = tagger.parse_to_node(line);

    let mut mecabu: Vec&lt;HashMap&lt;String, String&gt;&gt; = Vec::new();
    for node in nodes.iter_next() {
        match node.stat as i32 {
            mecab::MECAB_BOS_NODE =&gt; (),
            mecab::MECAB_EOS_NODE =&gt; (),
            _ =&gt; {
                mecabu.push(feature(&amp;node));
            }
        }
    }
    morph.push(mecabu);
}
for morph in morphs {
    for mecab in morph {
        println!("{}", format!("surface: {}, base: {}, pos: {}, pos1: {}", mecab["surface"], mecab["base"], mecab["pos"], mecab["pos1"]));
    }
    println!("");
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec31">31. 動詞</a></h3>

<p>動詞だけ抽出するので以下のコードで抽出し、表層形(<code>"surface"</code>)を取得する</p>

<p>```rust
fn verb(nodes: Vec&lt;HashMap&lt;String, String>>) &ndash;> Vec&lt;HashMap&lt;String, String>> {</p>

<pre><code>nodes.iter().filter(|m| m["pos"] == inspect(VERB)).map(|hm| hm.clone()).collect()
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec32">32. 動詞の原形</a></h3>

<p>動詞だけ抽出するので上記のコードで抽出し、原形(<code>"base"</code>)を取得する</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec33">33. サ変名詞</a></h3>

<p>サ変接続を抽出</p>

<p>```rust
fn sa_noun(nodes: Vec&lt;HashMap&lt;String, String>>) &ndash;> Vec&lt;HashMap&lt;String, String>>{</p>

<pre><code>noun(nodes).iter().filter(|node| node["pos1"] == "サ変接続").map(|hm| hm.clone()).collect()
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec34">34. 「AのB」</a></h3>

<p>「の」を挾んでいる名詞を抽出</p>

<p>```rust
fn between_noun(node: &amp;Node) &ndash;> Option<String> {</p>

<pre><code>let mecab = feature(node);
if mecab["surface"] == "の" &amp;&amp; mecab["pos"] == inspect(PARTICLE) &amp;&amp; mecab["pos1"] == "連体化" {
    let prev = feature(&amp;node.prev().unwrap());
    let next = feature(&amp;node.next().unwrap());

    Some(format!("{}{}{}", &amp;prev["surface"], &amp;mecab["surface"], &amp;next["surface"]))
} else {
    None
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec35">35. 名詞の連接</a></h3>

<p>連続した名詞を抽出するが、<code>mecab</code> でうまく関数化できなかったので割愛(あとでうかんだら追記)します。</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec36">36. 単語の出現頻度</a></h3>

<p>単純に頻度をまとめ、 <code>sort</code> するとよい</p>

<p>```rust
fn word_histgram(nodes: Vec&lt;HashMap&lt;String, String>>) &ndash;> HashMap&lt;String, u64> {</p>

<pre><code>let mut results: HashMap&lt;String, u64&gt; = HashMap::new();
for node in nodes {
    let base = &amp;node["base"];
    *results.entry(base.to_string()).or_insert(0) += 1;
}
results
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec37">37. 頻度上位10語</a></h3>

<p>上記の結果より <code>.take(10)</code> するだけです。</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec38">38. ヒストグラム</a></h3>

<p>37 と違いがわからずおわり。</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec39">39. Zipfの法則</a></h3>

<p>単純に両対数グラフ化でおわり。</p>

<h2>おわり</h2>

<p>おわり</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NLP 100 Knock section 3]]></title>
    <link href="http://blog.katsyoshi.org/blog/2018/02/09/nlp-100-section-3/"/>
    <updated>2018-02-09T23:53:24+09:00</updated>
    <id>http://blog.katsyoshi.org/blog/2018/02/09/nlp-100-section-3</id>
    <content type="html"><![CDATA[<p>正規表現苦手なようでだいぶ時間がかかりました。</p>

<h2><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#ch3">第3章 正規表現</a></h2>

<p>正規表現ときいて楽勝やろと思ってた時期もあったんですが・・・</p>

<h3>準備</h3>

<p>この章では、gzファイルに入ったJSONをパースする必要があるのでさきにgzファイルから読み込むようにします。</p>

<p>```rust
fn read_gzip(path: String) &ndash;> Vec<String> {</p>

<pre><code>let mut file = File::open(path).unwrap();
let mut string = String::new();
Decoder::new(&amp;mut file).unwrap().read_to_string(&amp;mut string).unwrap();
string.split("\n").filter(|m| m.ne(&amp;"")).map(|m| m.to_string()).collect::&lt;Vec&lt;String&gt;&gt;()
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec20">20. JSONデータの読み込み</a></h3>

<p>こいつは、<a href="https://docs.serde.rs/serde/"><code>serde</code></a> の <a href="https://docs.serde.rs/serde_json/index.html"><code>serde_json</code></a> を利用して <a href="https://docs.serde.rs/serde_json/fn.from_str.html"><code>from_str</code></a> で読み込むだけです。</p>

<p>```rust
let v: Value = match serde_json::from_str(&amp;l.as_str()) {</p>

<pre><code> Ok(v) =&gt; v,
 Err(_) =&gt; { continue; },
</code></pre>

<p>};
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec21">21. カテゴリ名を含む行を抽出</a> &amp;&amp; <a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec22">22. カテゴリ名の抽出</a></h3>

<p><a href="https://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8">早見表</a> を参考に <a href="https://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8">Regex::captures</a> で抽出することで解決。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>extern crate regex;
extern crate serde_json;</p>

<p>use serde_json::Value;
use regex::Regex;</p>

<p>fn main() {</p>

<pre><code>let args: Vec&lt;String&gt; = env::args().skip(1).collect();
let path = &amp;args[0].to_string();
let keywords = &amp;args[1..];
let file = File::open(path).unwrap();
let lines = BufReader::new(file).lines();
let re = Regex::new(r"\[\[Category:.+\]\]").unwrap();
let cap = Regex::new(r"\[\[Category:(?P&lt;name&gt;.+?)(?:\|.*)*\]\]").unwrap();

for l in lines {
    let v: Value = serde_json::from_str(&amp;l.unwrap()).unwrap();

    let title = &amp;v["title"].as_str().unwrap().to_string();
    if keywords.contains(title) {
        for content in v["text"].as_str().unwrap().to_string().split("\n").filter(|m| re.is_match(m)) {
            for c in cap.captures_iter(content) {
                println!("{}", &amp;c["name"]);
            }
        }
    }
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec23">23. セクション構造</a></h3>

<p>こちらは前節の問題と同様に解けばよいですが、<code>=の数 - 1</code> という罠があります。
```rust
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>extern crate regex;
extern crate serde_json;</p>

<p>use serde_json::Value;
use regex::Regex;</p>

<p>fn main() {</p>

<pre><code>let args: Vec&lt;String&gt; = env::args().skip(1).collect();
let path = &amp;args[0].to_string();
let keywords = &amp;args[1..];
let file = File::open(path).unwrap();
let lines = BufReader::new(file).lines();
let re = Regex::new(r"(?P&lt;level&gt;==+)(?P&lt;headline&gt;.+?)(?:=+)").unwrap();

for l in lines {
    let v: Value = serde_json::from_str(&amp;l.unwrap()).unwrap();

    let title = &amp;v["title"].as_str().unwrap().to_string();
    if keywords.contains(title) {
        for content in v["text"].as_str().unwrap().to_string().split("\n").filter(|m| re.is_match(m)) {
            for caps in re.captures_iter(content) {
                println!("level: {}, headline: {}", &amp;caps["level"].len() - 1, &amp;caps["headline"]);
            }
        }
    }
}
</code></pre>

<p>}</p>

<p>```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec24">24. ファイル参照の抽出</a></h3>

<p>このあたりは問題ないとおもいます。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>extern crate regex;
extern crate serde_json;</p>

<p>use serde_json::Value;
use regex::Regex;</p>

<p>fn main() {</p>

<pre><code>let args: Vec&lt;String&gt; = env::args().skip(1).collect();
let path = &amp;args[0].to_string();
let keywords = &amp;args[1..];
let file = File::open(path).unwrap();
let lines = BufReader::new(file).lines();
let re = Regex::new(r"\[\[(File|ファイル):(?P&lt;filename&gt;.+?)(?:\|.*)*(?:\|.*)*\]\]").unwrap();

for l in lines {
    let v: Value = serde_json::from_str(&amp;l.unwrap()).unwrap();

    let title = &amp;v["title"].as_str().unwrap().to_string();
    if keywords.contains(title) {
        for content in v["text"].as_str().unwrap().to_string().split("\n").filter(|m| re.is_match(m)) {
            for caps in re.captures_iter(content) {
                println!("filename: {}", &amp;caps["filename"]);
            }
        }
    }
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec25">25. テンプレートの抽出</a></h3>

<p>こいつは大変でしたので参考サイト<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> を参考に以下の正規表現でとりあえず抽出しています。</p>

<p><code>rust
let re = Regex::new(r"(?ms)(?:^\{\{基礎情報.*?$)(?P&lt;dict&gt;.+?)(?:^\}\}$)").unwrap();
</code></p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec26">26. 強調マークアップの除去</a></h3>

<p>こちらも同様に参考サイト<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>を参考に以下の正規表現で</p>

<p><code>rust
let strong = Regex::new(r"'{2,5}").unwrap();
</code></p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec27">27. 内部リンクの除去</a></h3>

<p>こちらも同様に参考サイト<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>を参考に以下の正規表現で
<code>rust
let link = Regex::new(r"(?:\[{1,2})(?P&lt;link&gt;.+?)(?:\|.+)?(?:\]{1,2})").unwrap();
</code></p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec28">28. MediaWikiマークアップの除去</a></h3>

<p>どうよう<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> (ry</p>

<p><code>
let link = Regex::new(r"(?:\[{1,2})(?P&lt;link&gt;.+?)(?:\|.+)?(?:\]{1,2})").unwrap();
let lang = Regex::new(r"(?:\{\{lang\|.+?\|)(?P&lt;lang&gt;.+?)(?:\}\})").unwrap();
let markup = Regex::new(r"&lt;/*.+?&gt;").unwrap();
</code></p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec29">29. 国旗画像のURLを取得する</a></h3>

<p>こちらもさんこおおう<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>にしてますが、主にURL部分だけです。
こちらは <a href="https://hyper.rs/">Hyper</a> を利用することで解決しています。</p>

<p>```rust
extern crate futures;
extern crate hyper;
extern crate hyper_tls;
extern crate libflate;
extern crate regex;
extern crate serde_json;
extern crate tokio_core;</p>

<p>use futures::{Future, Stream};
use hyper::Client;
use hyper_tls::HttpsConnector;
use libflate::gzip::Decoder;
use regex::Regex;
use serde_json::Value;
use std::collections::HashMap;
use std::env;
use std::fs::File;
use std::io::Read;
use tokio_core::reactor::Core;</p>

<p>fn get_image(query: String) &ndash;> String {</p>

<pre><code>let re = Regex::new(r" ").unwrap();
let uri = format!("https://en.wikipedia.org/w/api.php?action=query&amp;titles=File:{}&amp;format=json&amp;prop=imageinfo&amp;iiprop=url", re.replace_all(&amp;query, "%20"));
let uri = uri.parse().unwrap();
let mut core = Core::new().unwrap();
let handle = core.handle();
let client = Client::configure()
    .connector(HttpsConnector::new(4, &amp;handle).unwrap())
    .build(&amp;handle);
let work = client.get(uri).and_then(|res| {
    res.body().concat2().and_then(move |body| {
        let v: Value = serde_json::from_slice(&amp;body).unwrap();
        let page_ids = v["query"]["pages"].as_object().unwrap().keys().map(|m| m.to_string()).collect::&lt;Vec&lt;String&gt;&gt;();
        let imageinfo = &amp;v["query"]["pages"][&amp;page_ids[0]]["imageinfo"];
        let r = format!("{}", imageinfo[0]["url"].as_str().unwrap());
        Ok(r)
    })
});
core.run(work).unwrap()
</code></pre>

<p>}</p>

<p>fn read_gzip(path: String) &ndash;> Vec<String> {</p>

<pre><code>let mut file = File::open(path).unwrap();
let mut string = String::new();
Decoder::new(&amp;mut file).unwrap().read_to_string(&amp;mut string).unwrap();
string.split("\n").filter(|m| m.ne(&amp;"")).map(|m| m.to_string()).collect::&lt;Vec&lt;String&gt;&gt;()
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let args: Vec&lt;String&gt; = env::args().skip(1).collect();
let path = &amp;args[0].to_string();
let keywords = &amp;args[1..];
let lines = read_gzip(path.to_string());
let re = Regex::new(r"(?ms)(?:^\{\{基礎情報.*?$)(?P&lt;dict&gt;.+?)(?:^\}\}$)").unwrap();
let bar_hat = Regex::new(r"(?ms)(?:^\|)").unwrap();
let dict = Regex::new(r"(?P&lt;key&gt;.+?)\s*=\s*(?P&lt;val&gt;.+)").unwrap();
let media = Regex::new(r"\[\[(File|ファイル):(?P&lt;filename&gt;.+?)(?:\|.*)*(?:\|.*)*\]\]").unwrap();
let strong = Regex::new(r"'{2,5}").unwrap();
let link = Regex::new(r"(?:\[{1,2})(?P&lt;link&gt;.+?)(?:\|.+)?(?:\]{1,2})").unwrap();
let lang = Regex::new(r"(?:\{\{lang\|.+?\|)(?P&lt;lang&gt;.+?)(?:\}\})").unwrap();
let markup = Regex::new(r"&lt;/*.+?&gt;").unwrap();

for l in lines {
    let v: Value = match serde_json::from_str(&amp;l.as_str()) {
        Ok(v) =&gt; v,
        Err(_) =&gt; { continue; },
    };
    let text: String = match v["text"].as_str() {
        Some(x) =&gt; x.to_string(),
        None =&gt; { continue; },
    };
    let title: String = match v["title"].as_str() {
        Some(x) =&gt; x.to_string(),
        None =&gt; { continue; },
    };

    if keywords.contains(&amp;title) {
        let mut results: HashMap&lt;String, String&gt; = HashMap::new();
        let re: String = match re.captures(&amp;text) {
            Some(caps) =&gt; caps["dict"].to_string(),
            None =&gt; {
                println!("cannot capture dict!!");
                continue;
            },
        };
        for line in bar_hat.split(&amp;re).filter(|f| f.ne(&amp;"")).map(|m| m.to_string()) {
            let line = line.replace("\n", "");
            let dict = match dict.captures(&amp;line) {
                Some(x) =&gt; x,
                None =&gt; {continue;},
            };

            let val = dict["val"].to_string();
            let key = dict["key"].to_string();
            let file: String = media.replace_all(&amp;val, "$filename").trim().to_string();
            let strong: String = strong.replace_all(&amp;file, "").trim().to_string();
            let link: String = link.replace_all(&amp;strong, "$link").trim().to_string();
            let markup: String = markup.replace_all(&amp;link, "").trim().to_string();
            let val: String = match key.as_ref() {
                "国旗画像" =&gt; get_image(markup.to_string()),
                _ =&gt; lang.replace_all(&amp;markup, "$lang").trim().to_string(),
            };
            results.insert(key, val);
        }
        for (k, v) in results {
            println!("{}: {}", k, v);
        }
    }
}
</code></pre>

<p>}
```</p>

<h2>おわり</h2>

<p>とりあえず3章まで終わらせましたので形態素解析へと進みたいとおもいます(思っているだけ)</p>

<h2>参考資料</h2>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>素人の言語処理100本ノック:25, segavvy, <a href="https://qiita.com/segavvy/items/e402ad0a5b0f52453d7f">https://qiita.com/segavvy/items/e402ad0a5b0f52453d7f</a><a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>素人の言語処理100本ノック:26, segavvy, <a href="https://qiita.com/segavvy/items/f6d0f3d6eee5acc33c58">https://qiita.com/segavvy/items/f6d0f3d6eee5acc33c58</a><a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>素人の言語処理100本ノック:27, segavvy, <a href="https://qiita.com/segavvy/items/9a8137f045852bc299d6">https://qiita.com/segavvy/items/9a8137f045852bc299d6</a><a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>素人の言語処理100本ノック:28, segavvy, <a href="https://qiita.com/segavvy/items/8c4567ec1124320d3354">https://qiita.com/segavvy/items/8c4567ec1124320d3354</a><a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>素人の言語処理100本ノック:29, segavvy, <a href="https://qiita.com/segavvy/items/fc7257012d8a590185e5">https://qiita.com/segavvy/items/fc7257012d8a590185e5</a><a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NLP100ノック第2章]]></title>
    <link href="http://blog.katsyoshi.org/blog/2018/01/27/nlp-100-section-2/"/>
    <updated>2018-01-27T19:46:23+09:00</updated>
    <id>http://blog.katsyoshi.org/blog/2018/01/27/nlp-100-section-2</id>
    <content type="html"><![CDATA[<p>第2章を一通り終えたので書きます。</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec10">10. 行数のカウント</a></h3>

<p>タイトルのままです。 <code>Rust</code> では <a href="https://doc.rust-lang.org/std/str/struct.Lines.html"><code>std::str::Lines</code></a> で <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.count"><code>count()</code></a> がありますので利用しておわりです。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>fn main() {</p>

<pre><code>let mut args = env::args();

args.next();
for path in args {
    let f = File::open(path).unwrap();
    let br = BufReader::new(f);

    println!("{}", br.lines().count());
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec11">11. タブをスペースに置換</a></h3>

<p>コチラも、<a href="https://doc.rust-lang.org/std/string/struct.String.html#method.replace"><code>std::string::String.replace()</code></a> 利用するだけです。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>fn main() {</p>

<pre><code>let mut args = env::args();
args.next();
for path in args {
    let file = File::open(path).unwrap();
    let reader = BufReader::new(file);

    for line in reader.lines() {
        println!("{}", line.unwrap().replace("\t", " "));
    }
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec12">12. 1列目をcol1.txtに,2列目をcol2.txtに保存</a></h3>

<p>こちらは単純にファイルに書き込むのと、分割ができれば問題ないです。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::{BufReader, BufWriter, Write};
use std::io::prelude::*;</p>

<p>fn main() {</p>

<pre><code>let mut args = env::args();

args.next();
for path in args {
    let f = path.clone().replace(".txt", "");
    let s = path.clone().replace(".txt", "");
    let file = File::open(path).unwrap();
    let br = BufReader::new(file);
    let mut first_column = BufWriter::new(File::create(format!("{}_col1.txt", f)).unwrap());
    let mut second_column = BufWriter::new(File::create(format!("{}_col2.txt", s)).unwrap());

    for line in br.lines() {
        let words = line.unwrap().split("\t").map(|m| m.to_string()).collect::&lt;Vec&lt;String&gt;&gt;();
        first_column.write(format!("{}\n", words[0]).as_bytes()).unwrap();
        second_column.write(format!("{}\n", words[1]).as_bytes()).unwrap();
    }
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec13">13. col1.txtとcol2.txtをマージ</a></h3>

<p>こちらは以前利用した、<code>zip</code> があれば問題ないです。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::{BufReader, BufWriter, Write};
use std::io::prelude::*;</p>

<p>fn main() {</p>

<pre><code>let mut args = env::args();
if args.len() &lt; 2 { panic!("col1.txt col2.txt"); }

args.next();

let first = args.next().unwrap();
let second = args.next().unwrap();

let fr = BufReader::new(File::open(first).unwrap()).lines().map(|m| m.unwrap().to_string()).collect::&lt;Vec&lt;String&gt;&gt;();

let sr = BufReader::new(File::open(second).unwrap()).lines().map(|m| m.unwrap().to_string()).collect::&lt;Vec&lt;String&gt;&gt;();
let mut merge_file =
    BufWriter::new(File::create("merge.txt".to_string()).unwrap());

for (x, y) in fr.iter().zip(&amp;sr) {
    merge_file.write(format!("{}\t{}\n", x, y).as_bytes()).unwrap();
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec14">14. 先頭からN行を出力</a></h3>

<p><code>head</code> コマンドですので <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.take"><code>std::iter::Iterator.take()</code></a> を利用するだけです。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>fn main() {</p>

<pre><code>let args = env::args().skip(1).collect::&lt;Vec&lt;String&gt;&gt;();
let file = File::open(&amp;args[0]).unwrap();

let br = BufReader::new(file).lines().take((&amp;args[1]).to_string().parse::&lt;usize&gt;().unwrap());

for line in br.map(|m| m.unwrap().to_string()).collect::&lt;Vec&lt;String&gt;&gt;() {
    println!("{}", line);
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec15">15. 末尾のN行を出力</a></h3>

<p><code>tail</code> コマンドです。こちらは <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.skip"><code>std::iter::Iterator.skip()</code></a> を利用してやるだけです。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>fn main() {</p>

<pre><code>let args = env::args().skip(1).collect::&lt;Vec&lt;String&gt;&gt;();
let file = File::open(&amp;args[0]).unwrap();
let takes = (&amp;args[1]).to_string().parse::&lt;usize&gt;().unwrap();
let br = BufReader::new(&amp;file).lines();
let skips = br.count() - takes;
let file = File::open(&amp;args[0]).unwrap();
let lines = BufReader::new(&amp;file).lines().skip(skips);

for line in lines {
    println!("{}", line.unwrap());
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec16">16. ファイルをN分割する</a></h3>

<p>こちらの実装は素朴な実装とし、行数で分割しております。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::BufWriter;
use std::io::prelude::*;</p>

<p>fn main() {</p>

<pre><code>let args: Vec&lt;String&gt; = env::args().skip(1).collect();
let path = &amp;args[0].to_string();
let file = File::open(path).unwrap();
let count: usize = BufReader::new(file).lines().count();
let div: usize = (&amp;args[1]).to_string().parse().unwrap();
let file = File::open(path).unwrap();
let mut br = BufReader::new(file).lines();

let t = (count as f64/ div as f64).ceil() as usize;

for x in 1 .. div + 1 {
    let l = br.by_ref();
    let file = File::create(format!("{}.txt",x)).unwrap();
    let mut bw = BufWriter::new(file);
    for y in l.take(t).map(|m| m.unwrap().to_string()).collect::&lt;Vec&lt;String&gt;&gt;() {
        let a = format!("{}\n", y);
        bw.write(a.as_bytes()).unwrap();
        println!("{}: {}", x, y);
    }
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec17">17. 1列目の文字列の異なり</a></h3>

<p>ファイル読込 + <code>HashSet</code> で実装</p>

<p>```rust
use std::collections::HashSet;
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>extern crate regex;
use regex::Regex;</p>

<p>fn main() {</p>

<pre><code>let args: Vec&lt;String&gt; = env::args().skip(1).collect();
let path = &amp;args[0].to_string();
let file = File::open(path).unwrap();
let re = Regex::new(r"\W+").unwrap();
let hs = BufReader::new(file).lines().map(|m|{
    let l = m.unwrap().clone();
    re.split(&amp;l).next().unwrap().to_string()
}).collect::&lt;HashSet&lt;_&gt;&gt;();

for s in hs {
    println!("{}", s);
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec18">18. 各行を3コラム目の数値の降順にソート</a></h3>

<p>こちら、実数の比較を行う必要があり、すこし <a href="https://gist.github.com/katsyoshi/c76c2f782b3edaeff1d328a84dd582a0">めんどう</a> でした。</p>

<p>```rust
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>fn main() {</p>

<pre><code>let args: Vec&lt;String&gt; = env::args().skip(1).collect();
let path = &amp;args[0].to_string();
let file = File::open(path).unwrap();
let mut val = BufReader::new(file).lines().map(|m| m.unwrap().split("\t").skip(2).next().unwrap().parse::&lt;f64&gt;().unwrap()).collect::&lt;Vec&lt;f64&gt;&gt;();

val.sort_by(|a, b| a.partial_cmp(b).unwrap());
for v in val { println!("{}", v); }
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec19">19. 各行の1コラム目の文字列の出現頻度を求め,出現頻度の高い順に並べる</a></h3>

<p>18の問題を更にカウントできるように変更した。</p>

<p>```rust
use std::collections::HashMap;
use std::env;
use std::fs::File;
use std::io::BufReader;
use std::io::prelude::*;</p>

<p>enum Value {</p>

<pre><code>USIZE(usize),
NONE(()),
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let args = env::args().skip(1).collect::&lt;Vec&lt;String&gt;&gt;();
let file = File::open(&amp;args[0]).unwrap();
let mut words: HashMap&lt;String, usize&gt; = HashMap::new();
for m in BufReader::new(&amp;file).lines() {
    let w = m.unwrap().to_string().split("\t").next().unwrap().to_string();
    let v = match words.get(&amp;w) {
        None =&gt; 1,
        Some(n) =&gt; n + 1,
    };
    words.insert(w, v);
}

let mut vars: Vec&lt;(&amp;String, &amp;usize)&gt; = words.iter().collect();
vars.sort_by(|a, b| b.1.cmp(a.1));
for (w, v) in vars {println!("{}: {}", w, v);}
</code></pre>

<p>}
```</p>

<h2>おわり</h2>

<p>この章は慣れてきたのか比較的楽に解けています。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[nlp 100 section 1 part 3]]></title>
    <link href="http://blog.katsyoshi.org/blog/2018/01/21/nlp-100-section-1-part-3/"/>
    <updated>2018-01-21T10:23:02+09:00</updated>
    <id>http://blog.katsyoshi.org/blog/2018/01/21/nlp-100-section-1-part-3</id>
    <content type="html"><![CDATA[<p>前回、<a href="http://www.cl.ecei.tohoku.ac.jp/nlp100">言語処理100本ノック</a> の04までやったので05からやります。</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec05">05. ngram</a></h3>

<p>こいつはbi-gramを単語、文字二つを実装するひつようがあります</p>

<p>```rust
fn bigram(words: Vec<String>) &ndash;> Vec<String> {</p>

<pre><code>let mut bi: Vec&lt;String&gt; = Vec::new();
let mut i = 0;

loop {
    let w = i + 2;
    if w &gt; words.len() { break; }
    bi.push(words[i..w].join(""));
    i += 1;
}
bi
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let words = "I am an NLPer".split(' ').map(|m| m.to_string()).collect::&lt;Vec&lt;String&gt;&gt;();
println!("\n===word bi-gram");
for word in bigram(words) {
    println!("{}", word);
}

let words = "I am an NLPer".chars().map(|m| m.to_string()).collect::&lt;Vec&lt;String&gt;&gt;();
for word in bigram(words) {
    println!("\"{}\"", word);
}
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec06">06. 集合</a></h3>

<p>これは単純に <a href="https://doc.rust-lang.org/beta/std/collections/struct.HashSet.html"><code>HashSet</code></a> を利用して、解決します。<code>HashSet</code> の差集合は <a href="https://doc.rust-lang.org/beta/std/collections/struct.HashSet.html#method.difference"><code>difference</code></a> を利用し、和集合は <a href="https://doc.rust-lang.org/beta/std/collections/struct.HashSet.html#method.union"><code>union</code></a> を、積集合は <a href="https://doc.rust-lang.org/beta/std/collections/struct.HashSet.html#method.intersection"><code>intersection</code></a> をそれぞれ利用します。また、特定の要素が含有していることを判定するには <a href="https://doc.rust-lang.org/beta/std/collections/struct.HashSet.html#method.contains"><code>contains</code></a> を利用して判定します。</p>

<p>```rust
use std::collections::HashSet;</p>

<p>fn bigram(words: Vec<String>) &ndash;> HashSet<String> {</p>

<pre><code>let mut bi: HashSet&lt;String&gt; = HashSet::new();
let mut i = 0;

loop {
    let w = i + 2;
    if w &gt; words.len() { break; }
    bi.insert(words[i..w].join(""));
    i += 1;
}
bi
</code></pre>

<p>}</p>

<p>fn chars(s: String) &ndash;> Vec<String> {</p>

<pre><code>s.chars().map(|m| m.to_string()).collect::&lt;Vec&lt;String&gt;&gt;()
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let s1 = bigram(chars("paraparaparadise".to_string()));
let s2 = bigram(chars("paragraph".to_string()));

println!("===UNION===");
for x in s1.union(&amp;s2) {
    println!("{}", x);
}

println!("\n===DIFF===");
println!("===s1 - s2===");
for x in s1.difference(&amp;s2) {
    println!("{}", x);
}
println!("===s2 - s1===");
for x in s2.difference(&amp;s1) {
    println!("{}", x);
}

println!("\n===intersection===");
for x in s1.intersection(&amp;s2) {
    println!("{}", x);
}

println!("\n===INCLUDE===");
let se = "se";
println!("s1: {}", s1.contains(se));
println!("s2: {}", s2.contains(se));
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec07">07. テンプレートによる文生成</a></h3>

<p>これは <a href=""><code>format!</code></a> を使えば終りです。(問題意図ほんとこれなんか？)</p>

<p>```rust
fn string_template(x: i8, y: &amp;str, z: f32) &ndash;> String {</p>

<pre><code>format!("{}時の{}は{}", x, y, z)
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let string = string_template(12, "気温", 22.5);
println!("{}", string);
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec08">08. 暗号文</a></h3>

<p>ASCII以外の判定と、小文字のASCIIが判れば簡単です。</p>

<p>```rust
use std::ascii::AsciiExt;</p>

<p>fn cipher(src: &amp;str) &ndash;> String {</p>

<pre><code>let chars = src.chars().collect::&lt;Vec&lt;char&gt;&gt;();
let mut result: String = String::new();
for c in chars {
    let s = if c.is_ascii() {
        let var: u8 = c as u8;
        match var {
            97 ... 122 =&gt; (219 - (var)) as char,
            _ =&gt; c,
        }
    } else {
        c
    };
    result.push(s);
}
result
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>println!("{}", cipher("Today is fine."));
println!("{}", cipher(&amp;cipher("Today is fine.")));
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec09">09. Typoglycemia</a></h3>

<p>こちらは、 <code>Vec</code> に <code>shuffle</code> 的なものがないので、<a href="https://doc.rust-lang.org/rand"><code>rand</code></a> を呼び出して <a href="https://doc.rust-lang.org/rand/rand/trait.Rng.html#method.shuffle"><code>shuffle</code></a> を使います。</p>

<p>```rust
extern crate rand;
use rand::Rng;</p>

<p>fn words(src: &amp;str) &ndash;> Vec<String> {</p>

<pre><code>let mut result: Vec&lt;String&gt; = Vec::new();

for s in src.split(' ').collect::&lt;Vec&lt;&amp;str&gt;&gt;() {
    let mut chars = s.chars().collect::&lt;Vec&lt;char&gt;&gt;();
    if chars.len() &lt; 5 {
        result.push(s.to_string());
    } else {
        let last_index = chars.len() - 1;
        let first_char = chars[0];
        let last_char = chars[last_index];

        let rand_chars = &amp;mut chars[1..last_index];
        shuffle(rand_chars);
        let mut rand_string = String::new();
        for c in rand_chars { rand_string.push(*c) }
        result.push(format!("{}{}{}", first_char, rand_string, last_char));
    }
}
result
</code></pre>

<p>}</p>

<p>fn shuffle(chars: &amp;mut [char]) {</p>

<pre><code>rand::thread_rng().shuffle(chars);
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let paragraph = "I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .";

for w in words(paragraph) {
    println!("{}", w);
}
</code></pre>

<p>}
```</p>

<h2>おわり</h2>

<p>ということで <code>Rust</code> で言語処理100本ノック1章をやってみました。
最近 <code>Ruby</code> しか書いていなかったので、新鮮で楽しいですね <code>Rust</code> 。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NLP100本ノック section 1 part 2]]></title>
    <link href="http://blog.katsyoshi.org/blog/2018/01/19/nlp-100-section-1-part-2/"/>
    <updated>2018-01-19T20:05:49+09:00</updated>
    <id>http://blog.katsyoshi.org/blog/2018/01/19/nlp-100-section-1-part-2</id>
    <content type="html"><![CDATA[<p>前回、<a href="http://www.cl.ecei.tohoku.ac.jp/nlp100">言語処理100本ノック</a> の01までやったので02からやっていきます。</p>

<h2><code>extern crate nlp100;</code></h2>

<p>ってやれるように <a href="https://github.com/katsyoshi/zatsu/tree/master/rust/nlp100"><code>Cargo</code></a> を作成
<code>
cargo new nlp100
</code></p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec02">02. 「パトカー」+「タクシー」=「パタトクカシーー」</a></h3>

<p>これはムズカシイので素直に <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.zip"><code>zip</code></a> を利用する</p>

<p>```rust
fn concat(t: (Vec<char>, Vec<char>)) {</p>

<pre><code>let (f, s) = t;
let mut r = String::new();

for (x, y) in f.iter().zip(s.iter()) {
    r.push_str(&amp;format!("{}{}", x, y));
}
println!("{}", r);
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let p: Vec&lt;char&gt; = String::from("パトカー").chars().collect();
let t: Vec&lt;char&gt; = String::from("タクシー").chars().collect();
let f = (p, t);
concat(f);
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec03">03. 円周率</a></h3>

<p>この問題は思い切り勘違いしてたので、「これのどこが円周率なの？」って思ってました。こいつは <a href="https://doc.rust-lang.org/regex/regex/index.html"><code>Regex</code></a> を用いて単語毎に分解、単語毎に文字数数えて解決してます。</p>

<p>```rust
fn char_count_list(w: &amp;str) &ndash;> Vec<usize> {</p>

<pre><code>Regex::new(r"\W+").unwrap().split(w).map(|m| m.len()).collect()
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let pi = char_count_list("Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.");
println!("{:?}", pi);
</code></pre>

<p>}
```</p>

<h3><a href="http://www.cl.ecei.tohoku.ac.jp/nlp100/#sec04">04. 元素記号</a></h3>

<p>これは、英語版「水兵リーベー僕の船」ですので条件に合うときだけ1文字に変更します。</p>

<p>```rust
use std::collections::HashMap;</p>

<p>fn main() {</p>

<pre><code>let atomic_words: Vec&lt;&amp;str&gt; = "Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.".split(' ').collect();
let mut atomic_table = HashMap::new();
for (i, a) in atomic_words.iter().enumerate() {
    let chars = a.chars().map(|v| v.to_string()).collect::&lt;Vec&lt;String&gt;&gt;();
    let r = match i {
        0 | 4...8 | 14...15 | 18 =&gt; chars[0].to_string(),
        _ =&gt; chars[0..2].join(""),
    };
    atomic_table.insert(r, i + 1);
}

for (k, v) in &amp;atomic_table {
    println!("{}: {}", k, v);
}
</code></pre>

<p>}
```</p>

<h2>おわり</h2>

<p>やっぱり難しいのを実感</p>
]]></content>
  </entry>
  
</feed>
